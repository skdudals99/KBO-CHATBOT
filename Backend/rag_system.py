# rag_system.py
# ============================================
# âš¾ RAG ì‹œìŠ¤í…œ (LangChain + FAISS + OpenAI)
# ============================================

import os
import pandas as pd
from typing import List, Dict
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.documents import Document
from langchain_core.prompts import PromptTemplate
from dotenv import load_dotenv

load_dotenv()

class RAGSystem:
    def __init__(self, csv_path: str, vector_store_path: str = None):
        """
        RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            csv_path: final_final4_docs.csv ê²½ë¡œ
            vector_store_path: FAISS ì¸ë±ìŠ¤ ì €ì¥/ë¡œë“œ ê²½ë¡œ
        """
        self.csv_path = csv_path
        self.vector_store_path = vector_store_path
        self.embeddings = OpenAIEmbeddings(
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        self.llm = ChatOpenAI(
            model="gpt-4",
            temperature=0.3,
            openai_api_key=os.getenv("OPENAI_API_KEY")
        )
        self.vectorstore = None
        self.retriever = None
        
        # ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
        self._initialize_vectorstore()
    
    def _load_documents_from_csv(self) -> List[Document]:
        """CSVì—ì„œ ë¬¸ì„œ ë¡œë“œ"""
        print(f"ğŸ“‚ CSV ë¡œë“œ ì¤‘: {self.csv_path}")
        
        df = pd.read_csv(self.csv_path, encoding="utf-8-sig")
        print(f"âœ… ë¡œë“œ ì™„ë£Œ: {len(df)} í–‰")
        
        documents = []
        for idx, row in df.iterrows():
            # DOC_TEXTë¥¼ contentë¡œ
            content = str(row.get("DOC_TEXT", ""))
            
            # ë©”íƒ€ë°ì´í„° êµ¬ì„±
            metadata = {
                "season": int(row.get("SEASON_ID", 0)),
                "pitcher": str(row.get("PITCHER_NAME", "")),
                "batter": str(row.get("BATTER_NAME", "")),
                "pitcher_hand": str(row.get("PITCHER_HAND", "")),
                "batter_hand": str(row.get("BATTER_HAND", "")),
                "pitcher_pitch_type": str(row.get("PITCHER_BEST_PITCH_TYPE", "")),
                "batter_pitch_type": str(row.get("BATTER_BEST_PITCH_TYPE", "")),
                "row_id": idx
            }
            
            doc = Document(page_content=content, metadata=metadata)
            documents.append(doc)
        
        return documents
    
    def _initialize_vectorstore(self):
        """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” (ì €ì¥ëœ ê²ƒ ë¡œë“œ or ìƒˆë¡œ ìƒì„±)"""
        
        # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ê°€ ìˆìœ¼ë©´ ë¡œë“œ
        if self.vector_store_path and os.path.exists(self.vector_store_path):
            print(f"ğŸ“¦ ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì¤‘: {self.vector_store_path}")
            try:
                self.vectorstore = FAISS.load_local(
                    self.vector_store_path,
                    self.embeddings,
                    allow_dangerous_deserialization=True
                )
                print("âœ… ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ ë²¡í„° ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
                print("ğŸ”„ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
                self._create_new_vectorstore()
        else:
            print("ğŸ†• ìƒˆ ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
            self._create_new_vectorstore()
        
        # Retriever êµ¬ì„±
        self._setup_retriever()
    
    def _create_new_vectorstore(self):
        """ìƒˆ ë²¡í„° ìŠ¤í† ì–´ ìƒì„±"""
        # ë¬¸ì„œ ë¡œë“œ
        documents = self._load_documents_from_csv()
        
        # í…ìŠ¤íŠ¸ ë¶„í•  (í•œê¸€ ìµœì í™”)
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=500,
            chunk_overlap=50,
            separators=["\n\n", "\n", ".", ",", " ", ""]
        )
        split_docs = text_splitter.split_documents(documents)
        print(f"ğŸ“„ ë¶„í• ëœ ë¬¸ì„œ ìˆ˜: {len(split_docs)}")
        
        # ë²¡í„° ìŠ¤í† ì–´ ìƒì„±
        print("ğŸ”„ ì„ë² ë”© ìƒì„± ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        self.vectorstore = FAISS.from_documents(split_docs, self.embeddings)
        print("âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ")
        
        # ì €ì¥
        if self.vector_store_path:
            os.makedirs(os.path.dirname(self.vector_store_path), exist_ok=True)
            self.vectorstore.save_local(self.vector_store_path)
            print(f"ğŸ’¾ ë²¡í„° ìŠ¤í† ì–´ ì €ì¥ ì™„ë£Œ: {self.vector_store_path}")
    
    def _setup_retriever(self):
        """Retriever êµ¬ì„±"""
        self.retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": 5}  # ìƒìœ„ 5ê°œ ë¬¸ì„œ ê²€ìƒ‰
        )
        print("âœ… Retriever êµ¬ì„± ì™„ë£Œ")
    
    def query(self, question: str) -> Dict:
        """
        ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            
        Returns:
            {
                "answer": "ë‹µë³€ í…ìŠ¤íŠ¸",
                "sources": [ê´€ë ¨ ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸]
            }
        """
        if not self.retriever:
            return {
                "answer": "RAG ì‹œìŠ¤í…œì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "sources": []
            }
        
        try:
            print(f"\nğŸ” RAG ì§ˆì˜: {question}")
            
            # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            docs = self.retriever.get_relevant_documents(question)
            
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context = "\n\n".join([doc.page_content for doc in docs])
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = f"""ë‹¹ì‹ ì€ KBO(í•œêµ­í”„ë¡œì•¼êµ¬) ë§¤ì¹˜ì—… ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

ì»¨í…ìŠ¤íŠ¸:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€ ê°€ì´ë“œë¼ì¸:
1. ì»¨í…ìŠ¤íŠ¸ì— ì •ë³´ê°€ ìˆìœ¼ë©´ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ í•¨ê»˜ ë‹µë³€í•˜ì„¸ìš”.
2. ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ "ë°ì´í„°ì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë§í•˜ì„¸ìš”.
3. ì¶”ì¸¡í•˜ì§€ ë§ê³  ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
4. ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.

ë‹µë³€:"""
            
            # LLM í˜¸ì¶œ
            answer = self.llm.predict(prompt)
            
            # ì†ŒìŠ¤ ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            sources = []
            for doc in docs:
                sources.append({
                    "season": doc.metadata.get("season"),
                    "pitcher": doc.metadata.get("pitcher"),
                    "batter": doc.metadata.get("batter"),
                    "content_preview": doc.page_content[:100] + "..."
                })
            
            print(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ (ì†ŒìŠ¤: {len(sources)}ê°œ)")
            
            return {
                "answer": answer,
                "sources": sources
            }
            
        except Exception as e:
            print(f"âŒ RAG ì§ˆì˜ ì˜¤ë¥˜: {e}")
            return {
                "answer": f"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "sources": []
            }
    
    def search_similar_documents(self, query: str, k: int = 5) -> List[Document]:
        """ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰"""
        if not self.vectorstore:
            return []
        
        return self.vectorstore.similarity_search(query, k=k)


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (ì‹±ê¸€í†¤)
_rag_system_instance = None

def get_rag_system() -> RAGSystem:
    """RAG ì‹œìŠ¤í…œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _rag_system_instance
    
    if _rag_system_instance is None:
        data_dir = os.getenv("DATA_DIR", "./data")
        csv_path = os.path.join(data_dir, "final_final4_docs.csv")
        vector_store_path = os.getenv("VECTOR_STORE_PATH", "./data/vector_store")
        
        _rag_system_instance = RAGSystem(csv_path, vector_store_path)
    
    return _rag_system_instance


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    print("ğŸ§ª RAG ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    rag = get_rag_system()
    
    # í…ŒìŠ¤íŠ¸ ì§ˆì˜
    test_questions = [
        "2024ë…„ ê¹€ê´‘í˜„ê³¼ ìµœì •ì˜ ë§¤ì¹˜ì—…ì€ ì–´ë•Œ?",
        "ì–‘í˜„ì¢…ì´ ì¢Œíƒ€ìë¥¼ ìƒëŒ€í•  ë•Œ ì„±ì ì€?",
        "ì²´ì¸ì§€ì—…ì„ ì˜ ë˜ì§€ëŠ” íˆ¬ìˆ˜ëŠ” ëˆ„ê°€ ìˆì–´?"
    ]
    
    for q in test_questions:
        print(f"\n{'='*60}")
        result = rag.query(q)
        print(f"ì§ˆë¬¸: {q}")
        print(f"ë‹µë³€: {result['answer']}")
        print(f"ì†ŒìŠ¤ ìˆ˜: {len(result['sources'])}")